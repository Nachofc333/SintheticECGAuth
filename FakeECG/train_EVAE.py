import os
import glob
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader, TensorDataset, random_split
from sklearn.model_selection import KFold
from sklearn.metrics import confusion_matrix, roc_curve, auc
import matplotlib.pyplot as plt
import seaborn as sns
import collections
from tqdm import tqdm 
# Importar las bibliotecas necesarias
import wfdb  # Para trabajar con registros y anotaciones de datos fisiol칩gicos
import sys  # Para manipular el int칠rprete de Python
import collections
import neurokit2 as nk  # Para procesar y analizar se침ales fisiol칩gicas
from segment_signals import segmentSignals  # Funci칩n personalizada para segmentar se침ales
from sklearn.model_selection import train_test_split  # Para dividir datos en conjuntos de entrenamiento y prueba
from sklearn.model_selection import train_test_split, GridSearchCV, KFold  # Herramientas para validaci칩n cruzada y b칰squeda de hiperpar치metros
from sklearn import metrics  # Para evaluar el rendimiento del modelo
import matplotlib.pyplot as plt  # Para generar gr치ficos
from sklearn.metrics import RocCurveDisplay, confusion_matrix, recall_score, f1_score  # Para mostrar curvas ROC
from CVAE import ConditionalVAE
from VAE import EstandarVAE
from fastdtw import fastdtw
from scipy.spatial.distance import euclidean
from sklearn.preprocessing import MinMaxScaler

# Par치metros
num_classes = 90
latent_dim = 16
seq_length = 256
batch_size = 32
num_epochs = 80
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Par치metros constantes
FS = 500  # Frecuencia de muestreo
W_LEN = 256  # Longitud de la ventana para segmentar se침ales
W_LEN_1_4 = 256 // 4  # Un cuarto de la longitud de la ventana
W_LEN_3_4 = 3 * (256 // 4)  # Tres cuartos de la longitud de la ventana

def process_record(record_path, annotation_path):
    # Leer el registro desde el archivo
    record = wfdb.rdrecord(record_path)
    # Leer las anotaciones desde el archivo
    annotation = wfdb.rdann(annotation_path, 'atr')

    # Obtener la se침al y la frecuencia de muestreo
    signal = record.p_signal[:, 0]  # Solo el primer canal
    sampling_rate = record.fs

    # Procesar la se침al con NeuroKit para limpiarla
    signals, info = nk.ecg_process(signal, sampling_rate=sampling_rate)
    signal = signals["ECG_Clean"]  # Se침al limpia
    r_peaks_annot = info["ECG_R_Peaks"]  # Posiciones de los picos R

    # Segmentar latidos de la se침al
    segmented_signals, refined_r_peaks = segmentSignals(signal, r_peaks_annot)
    return segmented_signals

def process_person(person_folder, person_id):
    # Inicializar listas para almacenar segmentos y etiquetas
    all_segments = []
    all_labels = []
    segmentos = sorted(glob.glob(os.path.join(person_folder, '*.hea')))[:2]

    # Iterar sobre cada archivo en la carpeta de la persona
    for record_path in segmentos:
        base = record_path[:-4]  # Eliminar la extensi칩n del archivo
        annotation_path = base  # Ruta de las anotaciones

        # Procesar el archivo y segmentar los latidos
        segments = process_record(base, annotation_path)
        all_segments.extend(segments)  # Agregar segmentos
        all_labels.extend([person_id] * len(segments))  # Agregar etiquetas correspondientes

    # Convertir las listas en arrays de NumPy
    return np.array(all_segments), np.array(all_labels)

# Graficar las curvas de p칠rdida y precisi칩n
def plot_training_curves(history):
    # Obtener las m칠tricas del historial
    train_loss = history.history['loss']
    val_loss = history.history['val_loss']
    train_acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']
    epochs_range = range(1, len(history.history['loss']) + 1)

    # Configurar el tama침o de la figura
    plt.figure(figsize=(12, 5))

    # Subplot 1: Curvas de p칠rdida
    plt.subplot(1, 2, 1)
    plt.plot(epochs_range, train_loss, label='Training Loss')
    plt.plot(epochs_range, val_loss, label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.title('Loss Curve')
    plt.legend()

    # Subplot 2: Curvas de precisi칩n
    plt.subplot(1, 2, 2)
    plt.plot(epochs_range, train_acc, label='Training Accuracy')
    plt.plot(epochs_range, val_acc, label='Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.title('Accuracy Curve')
    plt.legend()

    plt.show()

# 游늷 Verifica si hay GPU disponible
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Usando dispositivo:", device)

# 游늷 Cargar datos
base_folder = "BBDD/ecg-id-database-1.0.0"
num_classes = 90
num_epochs = 200
batch_size = 32
X = []  # Lista para las se침ales
y = []  # Lista para las etiquetas

# Procesar los datos
"""for person_id, person_folder in enumerate(sorted(glob.glob(os.path.join(base_folder, 'Person_*')))):
    print(f"Procesando persona: {person_id}")
    segments, labels = process_person(person_folder, person_id)  # Funci칩n que procesa se침ales
    X.extend(segments)
    y.extend(labels)"""

person_id = 0
person_folder = os.path.join(base_folder, 'Person_01')
print(f"Procesando persona: {person_id}")
segments, labels = process_person(person_folder, person_id)  # Funci칩n que procesa se침ales
X.extend(segments)
y.extend(labels)

# Convertir datos a tensores de PyTorch
X = torch.tensor(np.array(X), dtype=torch.float32).unsqueeze(1)  # A침adir canal
y = torch.tensor(np.array(y), dtype=torch.long)
#y = F.one_hot(y, num_classes).float()

X_train, X_test= train_test_split(X, test_size=0.2, random_state=42)

# Guardar X_train en un archivo npy
np.save("FakeECG/X_trainEvae.npy", X_train.cpu().numpy())  # Guardar en formato NumPy

# 游늷 Dataset y DataLoader
train_dataset = TensorDataset(X_train)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

# 游늷 Instanciar modelo
cvae = EstandarVAE(in_channels=1, latent_dim=latent_dim, seq_length=seq_length).to(device)
optimizer = optim.Adam(cvae.parameters(), lr=0.001)

# 游늷 Funci칩n de p칠rdida
def loss_function(recon_x, x, mu, logvar):
    recon_loss = F.mse_loss(recon_x, x, reduction='sum')
    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())
    return recon_loss + kl_loss

# 游늷 Entrenamiento
for epoch in range(num_epochs):
    cvae.train()
    total_loss = 0
    for x in train_loader:
        x= x[0].to(device)
        optimizer.zero_grad()
        
        recon_x, _, mu, logvar = cvae(x)
        loss = loss_function(recon_x, x, mu, logvar)
        loss.backward()
        optimizer.step()
        
        total_loss += loss.item()

    print(f"Epoch {epoch+1}, Loss: {total_loss:.4f}")

# 游늷 Guardar modelo entrenado
torch.save(cvae.state_dict(), "FakeECG/Evae_model.pth")
print("Modelo guardado exitosamente en 'Evae_model.pth'")